{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../.images/logosnb.png\" alt=\"Banner\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='color: #690027;' markdown=\"1\">\n",
    "    <h1>OVERFITTING</h1> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voer onderstaande code-cel uit om van de functies in deze notebook gebruik te kunnen maken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp\n",
    "with open('../.scripts/diep_neuraal_netwerk.py', 'rb') as fp:\n",
    "    diep_neuraal_netwerk = imp.load_module('.scripts', fp, '../.scripts/diep_neuraal_netwerk.py', ('.py', 'rb', imp.PY_SOURCE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='color: #690027;' markdown=\"1\">\n",
    "    <h2>1. Wat is overfitting</h2> \n",
    "</div>\n",
    "\n",
    "Wanneer een netwerk te gefixeerd geraakt op de trainingdata zal het minder goed presteren op ongeziene data. Het netwerk leert dan als het ware de training data van buiten. Dit wordt <b>overfitting</b> genoemd. <br>\n",
    "Wanneer het netwerk nog kan bijleren, door bijvoorbeeld meer lagen toe te voegen, spreekt men van <b>underfitting</b>. <br>\n",
    "De volgende figuur stelt beide concepten visueel voor. Een diep neuraal netwerk zoekt als het ware een functie die de invoer afbeeldt op de juiste uitvoer en die goed genoeg generaliseert.\n",
    "\n",
    "<img src=\"../.images/IntroductieDeepLearning/overfitting.jpg\"/>\n",
    "\n",
    "Een netwerk kan ook overfitten op de validatiedata. Aan de hand van de prestaties van het netwerk op de validatiedata zal je het netwerk aanpassen om zo het beste netwerk te vinden voor je probleem. Elke keer dat je het netwerk aanpast aan de hand van de validatiedata leert het netwerk als het ware een klein beetje bij over deze data. Het finale netwerk zal dus beter presteren op deze data dan op echte ongeziene data. Daarom wordt andere data (de testdata) gebruikt om prestaties te meten van dit finale netwerk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='color: #690027;' markdown=\"1\">\n",
    "    <h2>2. Overfitting tegengaan</h2> \n",
    "</div>\n",
    "\n",
    "Overfitting is één van de meest voorkomende problemen bij het bouwen van een diep neuraal netwerk, gelukkig bestaan er verschillende technieken om overfitting tegen te gaan. Deze technieken worden ook wel <b>regularisatie</b>technieken genoemd.\n",
    "\n",
    "<div style='color: #690027;' markdown=\"1\">\n",
    "    <h3>2.1 Meer trainingdata</h3> \n",
    "</div>\n",
    "\n",
    "Hoe meer trainingdata je hebt, hoe minder waarschijnlijk het is dat je model snel zal overfitten. Hoe dit komt kan uitgelegd worden aan de hand van een voorbeeld. <br>\n",
    "Stel dat je een netwerk wilt trainen dat moet kunnen voorspellen of er een man of een vrouw op een pasfoto staat. Toevallig hebben alle mannen in de trainingdata een baard. Het netwerk kan de verkeerde conclusie trekken dat iedereen met een baard een man is en iedereen zonder baard een vrouw (het netwerk overfit op de trainingdata). Wanneer we de trainingdata uitbreiden zodat deze ook foto's bevat van mannen zonder baard zal het netwerk minder snel opnieuw die verkeerde conclussie trekken.\n",
    "\n",
    "Met meer data zal de data hoogstwaarschijnlijk ook meer gevarieerd zijn. Een probleem zoals hierboven beschreven zal dan minder snel zal voorvallen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='color: #690027;' markdown=\"1\">\n",
    "    <h3>2.2 Simpeler netwerk</h3> \n",
    "</div>\n",
    "\n",
    "Een complex netwerk met veel lagen en veel gewichten zal veel informatie over de trainingdata kunnen opslaan en dus sneller onbelangrijke details uit deze data van buiten kunnen leren, dit leidt tot overfitting. Een simpel netwerk (met minder lagen en neuronen) zal minder informatie kunnen opslaan en wordt dus gedwongen enkel de meest aanwezige kenmerken uit de trainingdata te gaan herkennen.\n",
    "\n",
    "Een methode om overfitting tegen te gaan is dus vertrekken vanuit een simpel netwerk en dit netwerk steeds complexer maken (lagen of neuronen toevoegen) tot je vaststelt dat het gaat overfitten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='color: #690027;' markdown=\"1\">\n",
    "    <h3>2.3 Data augmentation</h3> \n",
    "</div>\n",
    "\n",
    "Hoe meer trainingdata hoe beter, maar soms beschik je echter niet over heel veel trainingdata. Met data augmentation ga je de beschikbare trainingdata aanpassen zodat het netwerk steeds andere data te zien krijgt. Bij afbeeldingen kan je bijvoorbeeld de afbeelding een bepaald aantal graden draaien of je kan de afbeelding spiegelen over de x of de y-as. Je kan de intensiteit van de kleuren aanpassen of de afbeelding naar links, rechts, boven of onder verschuiven, enzovoort. Volgende afbeelding toont verschillende mogelijkheden van data augmentation op een afbeelding van een stoma. \n",
    "\n",
    "<img src=\"../.images/IntroductieDeepLearning/data_augmentatie.jpg\"/>\n",
    "\n",
    "De netwerken die in deze notebook gebruikt worden, maken gebruik van de volgende data augmentation om overfitting tegen te gaan:\n",
    "\n",
    "<ul>\n",
    "    <li><b>Horizontaal spiegelen</b>: Er wordt willekeurig gekozen of er al dan niet gespiegeld wordt over de y-as.</li>\n",
    "    <li><b>Verticaal spiegelen</b>: Er wordt willekeurig gekozen of er al dan niet gespiegeld wordt over de x-as.</li>\n",
    "    <li><b>Rotatie</b>: Er wordt willekeurig een getal gekozen tussen 0 en 180, daarna wordt de afbeelding met dit aantal graden geroteerd. Wanneer er op deze manier pixels te weinig zijn (in de hoeken), worden deze aangevuld door de dichtstbijzijnde pixel te herhalen.</li>\n",
    "</ul>\n",
    "\n",
    "Het verschuiven van de afbeelding zou in ons geval geen goed idee zijn omdat het netwerk op zoek moet gaan naar een stoma in het midden van de afbeelding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='color: #690027;' markdown=\"1\">\n",
    "    <h3>2.4 Dropout</h3> \n",
    "</div>\n",
    "\n",
    "Een zeer efficiënte en veelgebruikte methode van regularisatie is het toevoegen van dropout. Zoals vermeld in [BasisDiepNeuraalNetwerk](../IntroductieDeepLearning/BasisDiepNeuraalNetwerk.ipynb) bestaat een feedforward laag uit neuronen. Dropout zal er voor zorgen dat een willekeurig deel van deze neuronen geen uitvoer (dit komt overeen met een uitvoer van 0) meer geven en dus geen andere neuronen uit een volgende laag gaan activeren, ongeacht de gewichten van de verbindingen tussen deze neuronen. Het percentage van de neuronen waarvan de uitvoer naar 0 herleid wordt, wordt de <b>dropout rate</b> genoemd. Door steeds andere neuronen te kiezen wanneer het netwerk een afbeelding verwerkt, zal het netwerk minder makkelijk de trainingdata van buiten leren maar toch nog voldoende informatie krijgen om relevante patronen uit de trainingdata te leren.<br>\n",
    "De volgende afbeelding toont een netwerk zonder dropout en een netwerk waarbij er aan de twee middelste feedforward lagen dropout is toegevoegd met een dropout rate van 0,5. De cirkels stellen de neuronen voor en de lijnen de gewogen verbindingen tussen de verschillende lagen.\n",
    "\n",
    "<img src=\"../.images/IntroductieDeepLearning/dropout.jpg\"/>\n",
    "\n",
    "Dropout wordt enkel gebruikt tijdens het trainen van het netwerk, wanneer het netwerk wordt getest/gebruikt zullen dus alle neuronen normaal werken."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='color: #690027;' markdown=\"1\">\n",
    "    <h2>3. Het netwerk trainen met regularisatie</h2> \n",
    "</div>\n",
    "\n",
    "Als voorbeeld stel je opnieuw een netwerk samen. Deze keer wordt er echter gebruik gemaakt van de hiervoor beschreven data augmentation van de trainingdata en wordt er na elke feedforward laag dropout toegevoegd met een dropout rate van 0,5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "diep_neuraal_netwerk.kies_netwerk_parameters()\n",
    "diep_neuraal_netwerk.kies_training_parameters()\n",
    "diep_neuraal_netwerk.update_model('regularization', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na het kiezen van de netwerkarchitectuur en de trainingparameters kan je opnieuw het netwerk visualiseren met de volgende code-cel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "diep_neuraal_netwerk.toon_netwerk()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='color: #690027;' markdown=\"1\">\n",
    "    <h2>4. Resultaten</h2> \n",
    "</div>\n",
    "\n",
    "Overfitting is het best te zien op de grafiek van de loss-waarden over de verschillende epochs. Wanneer de training loss daalt maar de validatie loss begint te stijgen is er sprake van overfitting. Een netwerk met regularisatie zal echter (normaal gezien) pas later beginnen overfitten of helemaal niet overfitten (de validatie loss blijft ongeveer gelijk). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opdracht 4.1 \n",
    "Kies verschillende netwerken door de parameters hierboven aan te passen. Ga na welke netwerken overfitten en welke niet. Voer daarvoor de volgende code-cel uit. <br>\n",
    "Wanneer je de parameters van het netwerk aanpast, moet je de code-cel opnieuw uitvoeren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Gekozen netwerk met regularisatie\\n\")\n",
    "diep_neuraal_netwerk.toon_grafiek()\n",
    "\n",
    "print(\"Gekozen netwerk zonder regularisatie\\n\")\n",
    "diep_neuraal_netwerk.update_model('regularization', False)\n",
    "diep_neuraal_netwerk.toon_grafiek()\n",
    "diep_neuraal_netwerk.update_model('regularization', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../.images/cclic.png\" alt=\"Banner\" align=\"left\" style=\"width:80px;\"/><br><br>\n",
    "Notebook KIKS, zie <a href=\"http://www.aiopschool.be\">ai op school</a>, van F. wyffels, A. Meheus, T. Neutens & N. Gesquière is in licentie gegeven volgens een <a href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">Creative Commons Naamsvermelding-NietCommercieel-GelijkDelen 4.0 Internationaal-licentie</a>. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
