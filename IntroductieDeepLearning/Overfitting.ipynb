{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='color: #690027;' markdown=\"1\">\n",
    "    <h1>Overfitting</h1> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voer onderstaande codecel uit om van de methodes in deze notebook gebruik te kunnen maken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp\n",
    "with open('../.scripts/diep_neuraal_netwerk.py', 'rb') as fp:\n",
    "    diep_neuraal_netwerk = imp.load_module('.scripts', fp, '../.scripts/diep_neuraal_netwerk.py', ('.py', 'rb', imp.PY_SOURCE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='color: #690027;' markdown=\"1\">\n",
    "    <h2>1. Wat is overfitting</h2> \n",
    "</div>\n",
    "\n",
    "Wanneer een netwerk te gefixeerd geraakt op de training data zal het minder goed presteren op ongeziene data, het netwerk leert dan als het ware de training data van buiten. Dit wordt <b>overfitting</b> genoemd. Wanneer het netwerk nog kan bijleren, door bijvoorbeeld meer lagen toe te voegen, spreekt men van <b>underfitting</b>. Volgende figuur stelt beide concepten visueel voor, een diep neuraal netwerk zoekt als het ware een functie die de invoer afbeeld op de juiste uitvoer en die goed genoeg generaliseert.\n",
    "\n",
    "<img src=\"../.images/IntroductieDeepLearning/overfitting.jpg\"/>\n",
    "\n",
    "<div style='color: #690027;' markdown=\"1\">\n",
    "    <h2>2. Overfitting tegengaan</h2> \n",
    "</div>\n",
    "\n",
    "Overfitting is één van de meest voorkomende problemen bij het bouwen van een diep neuraal netwerk, gelukkig bestaan er verschillende technieken om overfitting tegen te gaan. Deze technieken worden ook wel <b>regularisatie</b> technieken genoemd.\n",
    "\n",
    "<div style='color: #690027;' markdown=\"1\">\n",
    "    <h2>2.1 Meer training data</h2> \n",
    "</div>\n",
    "\n",
    "Hoe meer training data je hebt hoe minder waarschijnlijk het is dat je model snel zal overfitten. De training data zal bijdragen aan de aanpassing van de gewichten van het netwerk tijdens het leren. Wanneer er meer training data is zal het model dus minder snel al deze data vanbuiten kunnen leren.\n",
    "\n",
    "<div style='color: #690027;' markdown=\"1\">\n",
    "    <h2>2.2 Simpeler netwerk</h2> \n",
    "</div>\n",
    "\n",
    "Een diep netwerk met veel lagen en gewichten zal veel informatie over de training data kunnen opslaan en leidt tot overfitting. Een te simpel netwerk zal dan weer niet genoeg leren uit de data. Het is vaak aangewezen om met een relatief simpel netwerk te starten en geleidelijk extra lagen of dimensies toe te voegen.\n",
    "\n",
    "<div style='color: #690027;' markdown=\"1\">\n",
    "    <h2>2.3 Data augmentation</h2> \n",
    "</div>\n",
    "\n",
    "Hoe meer training data hoe beter, soms heb je echter niet heel veel training data. Met data augmentation ga je je beschikbare training data aanpassen zodat het netwerk steeds andere data te zien krijgt. Bij afbeeldingen kan je bijvoorbeeld de afbeelding een bepaald aantal graden draaien of spiegelen over de x of de y-as. Je kan de intensiteit aanpassen, de afbeelding naar links, rechts, boven of onder verschuiven, enzovoort. Volgende afbeelding toont verschillende mogelijkheden van data augmentation op een afbeelding van een stoma. \n",
    "\n",
    "<img src=\"../.images/IntroductieDeepLearning/data_augmentatie.jpg\"/>\n",
    "\n",
    "De netwerken die in deze notebook gebruikt worden maken gebruik van volgende data augmentation om overfitting tegen te gaan:\n",
    "\n",
    "<ul>\n",
    "    <li><b>Horizontaal spiegelen</b>: Er wordt willekeurig gekozen of er al dan niet gespiegeld wordt over de y-as.</li>\n",
    "    <li><b>Verticaal spiegelen</b>: Er wordt willekeurig gekozen of er al dan niet gespiegeld wordt over de x-as.</li>\n",
    "    <li><b>Rotatie</b>: Er wordt willekeurig een getal gekozen tussen 0 en 180, daarna wordt de afbeelding met dit aantal graden geroteerd. Wanneer er op deze manier pixels te kort zijn (in de hoeken) worden deze aangevuld door de dichtstbijzijnde pixel te herhalen.</li>\n",
    "</ul>\n",
    "\n",
    "Het verschuiven van de afbeelding zou in ons geval geen goed idee zijn omdat het netwerk op zoek moet gaan naar een stoma in het midden van de afbeelding.\n",
    "\n",
    "<div style='color: #690027;' markdown=\"1\">\n",
    "    <h2>2.4 Dropout</h2> \n",
    "</div>\n",
    "\n",
    "Een zeer efficiënte en veelgebruikte methode van regularisatie is het toevoegen van dropout. Zoals vermeld in [BasisDiepNeuraalNetwerk](../IntroductieDeepLearning/BasisDiepNeuraalNetwerk.ipynb) bestaat een feedforward laag uit neuronen. Dropout zal er voor zorgen dat een willekeurig deel van deze neuronen geen uitvoer (dit komt overeen met een uitvoer van 0) meer geven en dus geen andere neuronen uit een volgende laag gaan activeren, ongeacht de gewichten tussen deze neuronen. Het percentage van de neuronen waarvan de uitvoer naar 0 herleid wordt wordt de <b>dropout rate</b> genoemd. Door steeds andere neuronen te kiezen wanneer het netwerk een afbeelding verwerkt zal het netwerk minder makkelijk de training data vanbuiten leren maar toch nog voldoende informatie krijgen om relevante patronen uit de training data te leren. Volgende afbeelding toont een netwerk zonder dropout en een netwerk waarbij er aan de 2 middelste feedforward lagen dropout is toegevoegd met een dropout rate van 0,5. De cirkels stellen de neuronen voor en de lijnen de gewichten tussen de verschillende lagen.\n",
    "\n",
    "<img src=\"../.images/IntroductieDeepLearning/dropout.jpg\"/>\n",
    "\n",
    "Dropout wordt enkel gebruikt tijdens het trainen van het netwerk, wanneer het netwerk wordt getest/gebruikt zullen dus alle neuronen normaal werken.\n",
    "\n",
    "<div style='color: #690027;' markdown=\"1\">\n",
    "    <h2>3. Het netwerk trainen met regularisatie</h2> \n",
    "</div>\n",
    "\n",
    "Als voorbeeld gaan we opnieuw een netwerk samenstellen, deze keer wordt er echter gebruik gemaakt van de hiervoor beschreven data augmentation van de training data en wordt er na elke feedforward laag dropout toegevoegd met een dropout rate van 0,5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diep_neuraal_netwerk.kies_netwerk_parameters()\n",
    "diep_neuraal_netwerk.kies_training_parameters()\n",
    "diep_neuraal_netwerk.update_model('regularization', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na het kiezen van de netwerk architectuur en de training parameters kunnen we opnieuw het netwerk visualiseren met volgende codecel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diep_neuraal_netwerk.toon_netwerk()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='color: #690027;' markdown=\"1\">\n",
    "    <h2>4. Resultaten</h2> \n",
    "</div>\n",
    "\n",
    "Overfitting is het best te zien door de grafiek van de loss waarden over de verschillende epochs te bekijken. Wanneer de training loss daalt maar de validatie loss begint te stijgen is er sprake van overfitting. Een netwerk met regularisatie zal echter (normaal gezien) pas later beginnen overfitten of helemaal niet overfitten (de validatie loss blijft ongeveer gelijk). \n",
    "\n",
    "<div style='color: #690027;' markdown=\"1\">\n",
    "    <h2>4.1 Opdracht</h2> \n",
    "</div>\n",
    "\n",
    "Kies verschillende netwerken door parameters hierboven aan te passen en kijk welke netwerken overfitten en welke niet door volgende codecel uit te voeren (Wanneer je de parameters van het netwerk aanpast moet je de codecel opnieuw uitvoeren)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Gekozen netwerk met regularisatie\\n\")\n",
    "diep_neuraal_netwerk.toon_grafiek()\n",
    "\n",
    "print(\"Gekozen netwerk zonder regularisatie\\n\")\n",
    "diep_neuraal_netwerk.update_model('regularization', False)\n",
    "diep_neuraal_netwerk.toon_grafiek()\n",
    "diep_neuraal_netwerk.update_model('regularization', True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
