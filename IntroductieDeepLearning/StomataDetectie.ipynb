{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='color: #690027;' markdown=\"1\">\n",
    "    <h1>Detectie van stomata</h1> \n",
    "</div>\n",
    "\n",
    "Voer onderstaande codecel uit om van de methodes in deze notebook gebruik te kunnen maken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp\n",
    "with open('../.scripts/diep_neuraal_netwerk.py', 'rb') as fp:\n",
    "    diep_neuraal_netwerk = imp.load_module('.scripts', fp, '../.scripts/diep_neuraal_netwerk.py', ('.py', 'rb', imp.PY_SOURCE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='color: #690027;' markdown=\"1\">\n",
    "    <h2>1. Het referentie model</h2> \n",
    "</div>\n",
    "\n",
    "In deze notebook wordt een diep neuraal netwerk gebruikt om stomata op een grote afbeelding te herkennen. Hoe zo een netwerk werkt en wat de onderdelen zijn kan je terugvinden in [BasisDiepNeuraalNetwerk](../IntroductieDeepLearning/BasisDiepNeuraalNetwerk.ipynb). Het netwerk waarvoor we hebben gekozen gebruikt de convolutionele lagen van het bestaande netwerk VGG19, heeft 1 feedforward laag met 1024 neuronen en gebruikt 'adam' als optimizer (i.p.v. SGD) met een learning rate van 0,0001. Het netwerk gebruikt ook dezelfde regularisatie technieken die beschreven zijn in [Overfitting](../IntroductieDeepLearning/Overfitting.ipynb). Volgende afbeelding geeft dit netwerk weer zoals de netwerken die we gezien hebben in [BasisDiepNeuraalNetwerk](../IntroductieDeepLearning/BasisDiepNeuraalNetwerk.ipynb).\n",
    "\n",
    "<img src=\"../.images/IntroductieDeepLearning/VGG19_netwerk.jpg\"/>\n",
    "\n",
    "Om dit netwerk in te laden voer je volgende codecel uit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diep_neuraal_netwerk.laad_referentie_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='color: #690027;' markdown=\"1\">\n",
    "    <h2>2. Stomata detectie in een volledige afbeelding</h2> \n",
    "</div>\n",
    "\n",
    "Momenteel kan het getrainde model een classificatie maken tussen 2 klassen (\"wel een stoma\" of \"geen stoma\") wanneer het een afbeelding van 120 pixels op 120 pixels krijgt als invoer. We willen echter dat alle stomata in een grote afbeelding (1600px op 1200px) gevonden kunnen worden met ons model. Om dit te verwezenlijken maken we gebruik van een <b>sliding window</b>. Dit is een vierkantje van 120px op 120px dat uit de grote afbeelding wordt geknipt en als invoer van het getrainde model wordt gebruikt. Voor dit vierkantje zal het model dan een voorspelling geven waarna het vierkantje naar rechts opschuift met 10 pixels. Wanneer het vierkantje de volledige breedte van de afbeelding heeft doorlopen zal het opnieuw naar de linkerkant verspringen maar dan 10 pixels lager dan de vorige keer. Dit proces herhaald zich tot de volledige afbeelding verwerkt werd met telkens sprongen van 10 pixels. Volgende afbeelding geeft een illustratie.\n",
    "\n",
    "<img src=\"../.images/IntroductieDeepLearning/sliding_window.gif\"/>\n",
    "\n",
    "Voor elke vierkantje uit de grote afbeelding zal er op deze manier een voorspelling gemaakt worden. Vaak zullen er meerdere vierkantjes rond de effectieve stoma een positieve uitvoer geven (\"wel een stoma\") omdat er slechts met 10 pixels wordt opgeschoven en dus niet veel verschil in de vierkantjes zit. Om deze vele positieve voorspellingen samen te voegen wordt er gebruik gemaakt van <b>clustering</b>. Clustering zal punten die dicht bij elkaar liggen als 1 cluster beschouwen en het middelpunt van deze clusters zijn dan de gevonden stomata. Volgende afbeelding geeft een voorbeeld van clustering waarbij de kleuren de verschillende clusters voorstellen en de grote punten de centers van de clusters.\n",
    "\n",
    "<img src=\"../.images/IntroductieDeepLearning/clustering.jpg\" width=\"400\"/>\n",
    "\n",
    "Bij de detectie speelt de <b>drempelwaarde</b> ook een belangrijke rol. Deze drempelwaarde bepaalt voor welke waarden van de uitvoer we de invoer als een stoma beschouwen. Als we bijvoorbeeld 0.5 als drempelwaarde nemen zal alle uitvoer groter dan 0.5 als \"wel een stoma\" beschouwd worden en alle uitvoer kleiner dan 0.5 als \"geen stoma\". \n",
    "\n",
    "Een belangrijke afweging die je moet maken bij het kiezen van de drempelwaarde is de verhouding tussen <b>precision</b> en <b>recall</b>. \n",
    "\n",
    "<ul>\n",
    "    <li>Precision: het percentage van de gevonden stomata dat ook daadwerkelijk stoma zijn.</li>\n",
    "    <li>Recall: het percentage van de totale aanwezige stomata op een afbeelding die gevonden werden.</li>\n",
    "</ul>\n",
    "\n",
    "Het is duidelijk dat een lage drempelwaarde zal zorgen voor een lage precision (er worden meer punten al stomata beschouwd, dus ook slechte punten) maar een hoge recall (er gaan ook meer echte stomata gevonden worden). Andersom geldt dit ook, een hoge drempelwaarde zal zorgen voor een hoge precision maar lage recall.\n",
    "\n",
    "Volgende codecel zal voor 3 afbeeldingen de stomata detecteren met het referentie netwerk. Je kan de drempelwaarde (thr) aanpassen en het resultaat interpreteren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diep_neuraal_netwerk.vind_stomata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='color: #690027;' markdown=\"1\">\n",
    "    <h2>3. Adversarial learning</h2> \n",
    "</div>\n",
    "\n",
    "Vaak is het mogelijk een diep neuraal netwerk te misleiden door opzettelijk verkeerde invoer te geven, dit wordt ook wel adversarial learning genoemd. Als we ons netwerk trainen gaan we ervan uit dat de uiteindelijke invoer er ongeveer zo uitziet als de data waarmee het netwerk getraind werd. Maar wat als dit nu niet het geval is? Kan ons netwerk een onderscheid maken tussen een microscopische afbeelding van een blad en een andere afbeelding? \n",
    "\n",
    "Voer volgende codecel uit om te zien hoe het netwerk reageert als we een foto van een kat als invoer geven."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diep_neuraal_netwerk.misleid_netwerk()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je kan zien dat het netwerk niet echt leert wat een stoma is maar gewoon een patronen leert herkennen. De ogen van de kat hebben ongeveer dezelfde vorm als een stoma en zullen dus ook als stoma gedetecteerd worden.\n",
    "\n",
    "In dit voorbeeld kreeg het netwerk een invoer die duidelijk verschilt van de gewenste invoer, maar dit is niet altijd het geval. Het is mogelijk een afbeelding zo te manipuleren dat het voor de mens dezelfde afbeelding lijkt maar een neuraal netwerk een totaal andere conclussie trekt. In een paper ([Explaining and Harnessing Adversarial Examples](https://arxiv.org/abs/1412.6572)) hebben enkele onderzoekers een afbeelding van een panda aangepast door ruiswaarden toe te voegen. Een diep neuraal netwerk dat afbeeldingen classificeerd was voor de aanpassing 57,7% zeker dat er een panda op de afbeelding stond, na de aanpassing dacht het netwerk met 99,3% zekerheid dat het om een gibbon ging.\n",
    "\n",
    "<img src=\"../.images/IntroductieDeepLearning/adversarial_learning.jpg\"/>\n",
    "\n",
    "Deze techniek kan ook misbruikt worden, denk maar aan een zelfrijdende auto die verkeersborden herkent met een diep neuraal netwerk. Iemand met kwade bedoelingen zou een normaal stopbord kunnen vervangen door een aangepast stopbord dat er gelijkaardig uitziet voor de mens maar niet kan gedetecteerd worden door het neurale netwerk van de auto.\n",
    "\n",
    "Andere voorbeelden zijn:\n",
    "<ul>\n",
    "    <li>Het aanpassen van spam emails om een spam filter te omzeilen.</li>\n",
    "    <li>Het namaken van een foto om toegang te krijgen tot een GSM met gezichtsherkenning.</li>\n",
    "    <li>...</li>\n",
    "</ul>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
