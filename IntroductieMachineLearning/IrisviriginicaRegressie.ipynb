{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../.images/logosnb.png\" alt=\"Banner\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='color: #690027;' markdown=\"1\">\n",
    "    <h1>REGRESSIE MET DATA OVER DE IRIS VIRGINICA</h1> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-box alert-success\">\n",
    "In deze notebook zie je hoe een <em>machinaal leren</em>-systeem erin slaagt een <b>best passende rechte</b> te vinden bij een gegeven verzameling van punten. Het algoritme vertrekt daarbij van een willekeurig gekozen rechte. Het algortime past de coëfficiënten in de vergelijking van deze rechte aan, gebaseerd op de gegeven data, totdat uiteindelijk de <b>regressielijn</b> wordt bekomen.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De Iris dataset werd in 1936 door de Brit Ronald Fischer gepubliceerd in 'The use of multiple measurements in taxonomic problems' [1][2].<br> \n",
    "De dataset betreft drie soorten irissen (*Iris setosa*, *Iris virginica* en *Iris versicolor*), 50 monsters van elke soort.\n",
    "Fischer kon de soorten van elkaar onderscheiden afgaande op vier kenmerken: de lengte en de breedte van de kelkbladen en de bloembladen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../.images/IntroductieMachineLearning/bloemblad_kelkblad.jpg\" alt=\"Drawing\" style=\"width: 400px;\"/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In deze notebook gebruik je enkel de gegevens over de lengte van de kelkblaadjes en de bloemblaadjes van de *Iris virginica*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### De nodige modules importeren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='color: #690027;' markdown=\"1\">\n",
    "    <h2>1. De data van de <em>Iris virginica</em></h2> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"../.images/IntroductieMachineLearning/Iris_virginica.jpg\" alt=\"Drawing\" style=\"width: 203px;\"/></center>\n",
    "<center>Figuur 1: *Iris virginica* [3]</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lees met de module `pandas` de dataset in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset inlezen\n",
    "virginica = pd.read_csv(\"../.data/IntroductieMachineLearning/virginica.dat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kijk de gegevens in. Dit kan zeer eenvoudig door de naam van de tabel in te geven. De lengte van enkele kelkblaadjes en van enkele bloemblaadjes worden weergegeven. Het aantal monsters is gemakkelijk af te lezen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset weergeven in tabel\n",
    "virginica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De relatie tussen de lengte van het kelkblad en de lengte van het bloemblad wordt bestudeerd. <br> Daarvoor wordt de lengte van het bloemblad uitgezet in functie van de lengte van het kelkblad. De lengte van het bloemblad komt dus op de y-as en de lengte van het kelkblad op de x-as."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-box alert-info\">\n",
    "Voor het machinaal leren-systeem zal de <em>lengte van het kelkblad</em> als <b>input</b> dienen en de <em>lengte van het bloemblad</em> als <b>output</b>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = virginica[\"lengte kelkblad\"]       # naam kolom als index gebruiken\n",
    "y = virginica[\"lengte bloemblad\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We zetten de data om naar NumPy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(x)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='color: #690027;' markdown=\"1\">\n",
    "    <h2>2. De samenhang tussen beide kenmerken visualiseren via een regressielijn</h2> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We standaardiseren de gegevens en geven ze weer in een puntenwolk. We berekenen de correlatiecoëfficiënt om te bekijken hoe sterk de samenhang tussen de twee kenmerken is.<br>\n",
    "Vervolgens wordt de regressielijn gezocht en getekend.<br>\n",
    "Met deze regressielijn wordt de lengte van een bloemblad voorspeld voor een gekende lengte van een kelkblad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='color: #690027;' markdown=\"1\">\n",
    "    <h3>2.1 De data standaardiseren</h3> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Om te standaardiseren wordt er overgegaan op de Z-scores van de kenmerken.<br>\n",
    "Voor meer uitleg over het belang van standaardiseren verwijzen we naar de notebook 'Standaardiseren'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = (x-np.mean(x))/np.std(x)\n",
    "y = (y-np.mean(y))/np.std(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='color: #690027;' markdown=\"1\">\n",
    "    <h3>2.2 De gestandaardiseerde data weergeven in puntenwolk</h3> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lengte bloemblad t.o.v. lengte kelkblad\n",
    "# lengte kelkblad komt op x-as, lengte bloemblad komt op y-as\n",
    "plt.scatter(x, y, color=\"blue\", marker=\"o\")  # puntenwolk\n",
    "\n",
    "plt.title(\"Iris virginica gestandaardiseerd\")\n",
    "plt.xlabel(\"lengte kelkblad\")          # xlabel geeft een omschrijving op de x-as\n",
    "plt.ylabel(\"lengte bloemblad\")         # ylabel geeft een omschrijving op de y-as\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))    # om een grotere grafiek te krijgen, zodat punten meer verspreid liggen\n",
    "# bereik zo kiezen opdat geschikt voor grotere en kleinere blaadjes\n",
    "plt.xlim(x.min()-2, x.max()+3)\n",
    "plt.ylim(y.min()-2, y.max()+3)\n",
    "plt.scatter(x, y, color=\"blue\", marker=\"o\")\n",
    "\n",
    "plt.title(\"Iris virginica gestandaardiseerd\")\n",
    "plt.xlabel(\"lengte kelkblad\")          \n",
    "plt.ylabel(\"lengte bloemblad\")         \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='color: #690027;' markdown=\"1\">\n",
    "    <h3>2.3 Samenhang tussen x en y?</h3> \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in hoeverre is er een verband tussen de x- en y- coördinaat van deze punten? \n",
    "# correlatiecoefficiënt bepalen (ligt tussen -1 en 1, hoe dichter bij 0, hoe slechter de samenhang)\n",
    "r = np.corrcoef(x, y)[0,1]\n",
    "print(\"R = \", r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zeer goede samenhang!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='color: #690027;' markdown=\"1\">\n",
    "    <h3>2.4 Regressielijn</h3> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bepaal de regressielijn met ingebouwde functies van de module scikit-learn, een Python-module met machine learning algoritmes. <br> Om zo'n algoritme te kunnen gebruiken, moet de *data in het gewenste formaat* worden aangeboden. Voor de y-waarden volstaat een 1D-array, maar voor de x-waarden moet de 1D-array worden omgezet naat een 2D-array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lineaire regressie\n",
    "X = x[:, np.newaxis]          # data in gewenste formaat aanbieden aan ML-systeem\n",
    "rechte = LinearRegression()   # rechte wordt bepaald met lineaire regressie\n",
    "rechte.fit(X, y)              # deze rechte moet passen bij data (X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R² en de gemiddelde kwadratische afwijking berekenen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# belangrijke getallen\n",
    "print(\"R² voor de rechte m.b.t. de data: %.3f\" % r2_score(y, rechte.predict(X)))\n",
    "print(\"Gemiddelde kwadratische afwijking voor de rechte m.b.t. de data: %.2f\"% mean_squared_error(y, rechte.predict(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grafiek van puntenwolk en regressielijn laten zien:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grafiek van puntenwolk en regressielijn\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.xlim(x.min()-2, x.max()+3)\n",
    "plt.ylim(y.min()-2, y.max()+3)\n",
    "plt.title(\"Iris virginica gestandaardiseerd\")\n",
    "plt.xlabel(\"lengte kelkblad\")          # xlabel geeft een omschrijving op de x-as\n",
    "plt.ylabel(\"lengte bloemblad\")         # ylabel geeft een omschrijving op de y-as\n",
    "\n",
    "plt.scatter(x, y, color=\"blue\", marker=\"o\")     # puntenwolk\n",
    "plt.plot(x, rechte.predict(X), color='green')   # gevonden regressielijn\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uit het model kan je rechtstreeks de richtingscoëfficiënt van de regressielijn bepalen en waar ze de y-as snijdt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# berekenen rico en doorgang y-as\n",
    "x_O = np.array([0])\n",
    "X_O = x_O[:, np.newaxis]     # data aanbieden in gewenste formaat\n",
    "y_O_predict = rechte.predict(X_O)\n",
    "x_1 = np.array([1])\n",
    "X_1 = x_1[:, np.newaxis]     # data aanbieden in gewenste formaat\n",
    "y_1_predict = rechte.predict(X_1)\n",
    "print(\"De regressielijn snijdt de y-as in: %.3f\" % y_O_predict)\n",
    "print(\"De regressielijn heeft als rico: %.3f\" % (y_1_predict - y_O_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='color: #690027;' markdown=\"1\">\n",
    "    <h3>2.5 Voorspellingen doen met het model</h3> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je kan met het model gebruiken voorspellingen doen bij nieuwe data: bv. de lengte van het bloemblad voorspellen als je de lengte van een kelkblad kent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lengte bloemblad voorspellen bij gekende lengte kelkblad\n",
    "x_gekend = np.array([3])               # kelkblad met gestandaardiseerde lengte gelijk aan 3\n",
    "X_gekend = x_gekend[:, np.newaxis]     # data aanbieden in gewenste formaat\n",
    "y_predict = rechte.predict(X_gekend)   # lengte bloemblad bepalen met model\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.xlim(x.min()-2, x.max()+3)\n",
    "plt.ylim(y.min()-2, y.max()+3)\n",
    "plt.title(\"Iris virginica gestandaardiseerd\")\n",
    "plt.xlabel(\"lengte kelkblad\")          \n",
    "plt.ylabel(\"lengte bloemblad\")         \n",
    "\n",
    "x_nieuw =  np.linspace(-4, 4, 67)      # rechte langer tekenen\n",
    "X_nieuw = x_nieuw[:, np.newaxis]       # gewenste formaat\n",
    "\n",
    "plt.scatter(x, y, color=\"blue\", marker=\"o\")     # puntenwolk\n",
    "plt.plot(x, rechte.predict(X), color='green')   # gevonden regressielijn\n",
    "plt.plot(x_nieuw, rechte.predict(X_nieuw), color='yellow')   # gevonden regressielijn verlengd\n",
    "plt.plot(x_gekend[0], y_predict[0], color = \"black\", marker = \"o\")  # voorspelde punt\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"Bij een kelkblad met gestandaardiseerde lengte \" + str(x_gekend[0]) + \n",
    "      \" is de gestandaardiseerde lengte van het bloemblad bij benadering \" + str(y_predict[0]) + \".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probeer eens hetzelfde met een andere afmeting voor het kelkblad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='color: #690027;' markdown=\"1\">\n",
    "    <h2>3. Stap voor stap op zoek naar de regressielijn</h2> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='color: #690027;' markdown=\"1\">\n",
    "    <h3>3.1 Opbouw van het algoritme</h3> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zo'n regressielijn wordt gezocht met een algoritme. Hier zie je hoe zo'n algoritme is opgebouwd.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Er wordt nog steeds met dezelfde gestandaardiseerde data x en y gewerkt. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-box alert-info\">\n",
    "Om een rechte te vinden die goed bij de gegeven data past, vertrekt het ML-systeem van een willekeurig gekozen rechte. Dit gebeurt door de richtingscoëfficiënt en het snijpunt met de y-as van deze rechte willekeurig te kiezen.<br>  \n",
    "Het systeem wordt *getraind* met de trainingset (de inputs en de corresponderende outputs): Voor elk punt van de trainingset wordt nagegaan hoeveel de corresponderende y-waarde op de voorlopige rechte afwijkt van de gegeven y-waarde. De coëfficiënten in de vergelijking van de rechte worden aangepast zodat de gemiddelde afwijking voor de hele datset minimaal is. <br>\n",
    "De volledige trainingset wordt een aantal keer doorlopen. Zo'n keer noemt men een *epoch*. Het systeem *leert* gedurende deze *pogingen ('epochs')*.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainingset met input x en output y\n",
    "print(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Het systeem moet de gemiddelde kwadratische afwijking kunnen berekenen van de datapunten tot de bepaalde rechte.<br>Daartoe wordt voor elk punt het residu $y-\\hat{y}$ berekend. Hierbij is $y$ de gegeven y-waarde en $\\hat{y}$ de voorspelde waarde, nl. de waarde die men bekomt door de gegeven x-waarde in te vullen in de vergelijking van de rechte.<br> De kwadraten van de residu's worden bij elkaar opgeteld. Deze som gedeeld door het aantal datapunten is de gezochte fout. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gka(b, a, x, y):\n",
    "    \"\"\"Gemiddelde kwadratische afwijking berekenen van punten tot rechte.\"\"\"\n",
    "    \n",
    "    totale_afw = 0\n",
    "    n = len(x)            # aantal punten\n",
    "    y_rechte = a * x + b  # y-waarden voor een bepaalde rechte\n",
    "    \n",
    "    # som kwadratische afwijkingen bij alle punten\n",
    "    for i in range(n):\n",
    "        totale_afw += (y[i] - y_rechte[i]) ** 2  \n",
    "    \n",
    "    return totale_afw/50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als voorbeeld kan je de gemiddelde kwadratische afwijking laten berekenen t.o.v. de x-as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gemiddelde kwadratische afwijking van de tariningdata t.o.v. de rechte y = 0\n",
    "fout = gka(0,0,x,y)\n",
    "print(fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-box alert-info\">\n",
    "Het ML-systeem vertrekt van een willekeurige rechte met vergelijking *y = mx + q*. Bij het begin van de training worden *m* en *q* gekozen. Ook het aantal *epochs* en de *learning rate* $\\eta$ worden vastgelegd.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Het algoritme zal de coëfficiënten van de rechte zo bepalen dat de fout geminimaliseerd wordt. Het doet dat met de methode **gradient descent**.<br>\n",
    "Na elke *epoch* worden de coëfficiënten aangepast, afhankelijk van de waarden van de partiële afgeleiden en de *learning rate*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(q, m, x, y, eta):\n",
    "    \"\"\"Aanpassing parameters q en m na voltooide epoch met learning rate eta.\"\"\"\n",
    "    \n",
    "    n = len(x)\n",
    "    y_huidig = m * x + q      # gevonden rechte op bepaald moment in proces\n",
    "    afgeleide_m = 0           # partiële afgeleide naar m declareren en initialiseren\n",
    "    afgeleide_q = 0           # partiële afgeleide naar q declareren en initialiseren\n",
    "    \n",
    "    # berekenen van de partiële afgeleiden\n",
    "    for i in range(n):\n",
    "        afgeleide_m += - (2/n) * x[i] * (y[i] - y_huidig[i])\n",
    "        afgeleide_q += - (2/n) * (y[i] - y_huidig[i])\n",
    "    \n",
    "    # waarden van m en q aanpassen\n",
    "    m = m - eta * afgeleide_m\n",
    "    q = q - eta * afgeleide_q\n",
    "     \n",
    "    # aangepaste waarden van m en q teruggeven\n",
    "    return q, m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='color: #690027;' markdown=\"1\">\n",
    "    <h3>3.2 Uittesten van het algoritme van gradient descent voor meerdere epochs</h3> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neem 0 als initiële waarde voor m en voor q. Voer gradient descent uit voor 3000 epochs met learning rate 0,01 en waarbij de aanpassingen van $m$ en $q$ en de fout na elke *epoch* wordt getoond. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# algoritme testen\n",
    "q=0\n",
    "m=0\n",
    "eta = 0.01\n",
    "\n",
    "for j in range(3000):\n",
    "    fout = gka(q,m,x,y)                    # gemiddelde kwadratische afwijking berekenen na elke epoch\n",
    "    print(q, m, fout)                      # waarden q, m en fout tonen na elke epoch\n",
    "    q, m = gradient_descent(q,m,x,y,eta)   # waarden q en m aanpassen na elke epoch \n",
    "    \n",
    "print(\"De rechte snijdt de y-as in: %.3f\" % q)\n",
    "print(\"De rechte heeft als rico: %.3f\" % m)\n",
    "print(\"Gemiddelde kwadratische afwijking voor de rechte m.b.t. de data: %.2f\"% fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In het voorbeeld zie je dat het aantal epochs mee zal bepalen hoe nauwkeurig de regressielijn wordt bepaald. De rechte die men heeft gevonden na bv. 50 epochs ligt nog zeer ver van de beoogde regressielijn. Kijk ook hoe de fout verloopt, zolang deze blijft dalen is ze nog niet geminimaliseerd, het systeem *underfit* dan.<br>\n",
    "Je ziet in het voorbeeld ook dat er te veel epochs zijn, op een gegeven moment neemt de fout niet meer af en worden de waarden niet meer aangepast. Dat betekent dat het minimum is bereikt.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je kan ook de *learning rate* eens aanpassen of de initiële waarden van m en q en kijken wat dit als effect heeft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='color: #690027;' markdown=\"1\">\n",
    "    <h3>3.3 Hoe verandert de fout en de stand van de rechte gedurende het proces?</h3> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Het proces om de regressielijn te bepalen bij gegeven data (x,y) hangt af van de startwaarden van m en q, van de *learning rate* (eta) en het aantal keer dat de data worden doorlopen (epochs). <br>\n",
    "Om de evolutie van de stand van de rechte en van de grootte van de fout te bekijken, moeten gaandeweg het proces de waarden van m, q en de fout na elke epoch worden opgeslagen.<br>\n",
    "Er worden daarvoor drie lijsten aangemaakt die na elke epoch worden aangevuld."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_proces(x, y, q, m, eta, epochs):\n",
    "    \"\"\"Proces doorlopen en gaandeweg ijsten maken van q, m en fout.\"\"\"\n",
    "    lijst_fout = [gka(q, m, x, y)]      # foutenlijst declareren en initialiseren\n",
    "    lijst_q = [q]                       # lijst van q's declareren en initialiseren\n",
    "    lijst_m = [m]                       # lijst van rico's declareren en initialiseren\n",
    "\n",
    "    # Voor elke epoch lijsten aanvullen\n",
    "    for i in range(epochs):\n",
    "        q, m = gradient_descent(q, m, x, y, eta)    # aangepaste parameters na epoch\n",
    "        fout = gka(q, m, x, y)                      # kost na epoch \n",
    "        lijst_q.append(q)                           # aangepaste q toevoegen\n",
    "        lijst_m.append(m)                           # aangepaste m toevoegen\n",
    "        lijst_fout.append(fout)                     # deze kost toevoegen\n",
    "\n",
    "    return [lijst_q, lijst_m, lijst_fout]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dit algoritme doorlopen voor gekozen *m*, *q*, *epochs* en *learning rate*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialisatie van m en q\n",
    "m = 0\n",
    "q = 0\n",
    "\n",
    "# vastleggen van aantal epochs en learning rate èta\n",
    "eta = 0.01 \n",
    "epochs = 500 \n",
    "\n",
    "# algoritme lineaire regressie doorlopen voor keuze m, q, èta en epochs\n",
    "lijst_q, lijst_m, lijst_fout = gradient_descent_proces(x, y, q, m, eta, epochs)\n",
    "\n",
    "# regressielijn\n",
    "print (\"Doorgang y-as: %.3f\" % lijst_q[-1])\n",
    "print (\"Rico: %.3f\" % lijst_m[-1])\n",
    "\n",
    "# gemiddelde kwadratische afwijking regressielijn\n",
    "print (\"Geminimaliseerde fout: %.2f\" %  lijst_fout[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voor dit proces een animatie maken:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alle rechten\n",
    "xcoord =  np.linspace(-4, 4, 67) \n",
    "\n",
    "ycoord = []\n",
    "for j in range(epochs):\n",
    "    y_r = lijst_m[j] * xcoord + lijst_q[j]         # y-waarde berekenen van alle x'n uit xcoord voor betreffende rechte\n",
    "    ycoord.append(y_r)\n",
    "ycoord = np.array(ycoord)    # type casting\n",
    "\n",
    "# plot-venster initialiseren\n",
    "fig, ax = plt.subplots()\n",
    "line, = ax.plot(xcoord, ycoord[0], color=\"green\")   # rechte plotten\n",
    "plt.scatter(x, y, color=\"blue\", marker=\"o\")         # puntenwolk\n",
    "ax.axis([x.min()-2,x.max()+3,y.min()-2,y.max()+3])  # bereik assen\n",
    "plt.title(\"Iris virginica gestandaardiseerd\")\n",
    "plt.xlabel(\"lengte kelkblad\")          # xlabel geeft een omschrijving op de x-as\n",
    "plt.ylabel(\"lengte bloemblad\")         # ylabel geeft een omschrijving op de y-as\n",
    "\n",
    "\n",
    "def animate(i):\n",
    "    line.set_ydata(ycoord[i])    # update de vergelijking van de rechte  \n",
    "    return line,\n",
    "\n",
    "plt.close()  # om voorlopig plot-venster te sluiten, enkel animatiescherm nodig\n",
    "\n",
    "anim = animation.FuncAnimation(\n",
    "    fig, animate, repeat=False, frames=len(ycoord))\n",
    "    \n",
    "HTML(anim.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grafiek evolutie fout\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(lijst_fout)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('gemiddelde kwadratische afwijking')\n",
    "plt.title('Evolutie van de fout')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimenteer nu zelf. Laat het algoritme doorlopen voor zelfgekozen *m*, *q*, *epochs* en *learning rate*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Lineaire regressie komt ook aan bod in de notebook 'Zeeniveau' en de notebook 'Hoogte bomen en afmetingen stomata in het Amazonewoud'.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <h2>Referentielijst</h2> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] Dua, D., & Karra Taniskidou, E. (2017). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. <br> &nbsp; &nbsp; &nbsp; &nbsp; Irvine, CA: University of California, School of Information and Computer Science.<br>\n",
    "[2] Fisher, R. A. (1936). The use of multiple measurements in taxonomic problems. *Annals of Eugenics*. 7(2), 179–188. <br> &nbsp; &nbsp; &nbsp; &nbsp; https://doi.org/10.1111/j.1469-1809.1936.tb02137.x.<br>\n",
    "[3] No machine-readable author provided. Dlanglois assumed (based on copyright claims). <br> &nbsp; &nbsp; &nbsp; &nbsp;\n",
    "[CC BY-SA 3.0 (http://creativecommons.org/licenses/by-sa/3.0/)], via Wikimedia Commons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../.images/cclic.png\" alt=\"Banner\" align=\"left\" style=\"width:80px;\"/><br><br>\n",
    "Notebook KIKS, zie <a href=\"http://www.aiopschool.be\">ai op school</a>, van F. wyffels & N. Gesquière is in licentie gegeven volgens een <a href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">Creative Commons Naamsvermelding-NietCommercieel-GelijkDelen 4.0 Internationaal-licentie</a>."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
